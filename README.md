# Системы мониторинга с использованием Spring Kafka
Система представляет собой систему мониторинга, которая получает метрики о работе различных компонентов
приложения с помощью Spring Kafka. Эта система включает в себя Producer для отправки
метрик, Consumer для их обработки и сохранения, а также REST API для просмотра, отправки и генерирования метрик.

С текстом задания можно ознакомиться в папке **docs** в корне проекта
## Структура приложения
Приложение состоит из 2х микросервисов **metricsConsumer** и **metricsProducer**.

![Структура приложения.png](docs%2F%D0%A1%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0%20%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F.png)

В **metricsProducer** реализованно следующее API  для взаимодействия с микросервисом:
* **POST** `/metrics` -  Отправка метрик работы приложения в формате JSON.
*  **GET** `/metrics/send/micrometer`- Получение метрик из сервиса **micrometer** и последующая отправка в формате JSON.

В **metricsConsumer** реализованно следующее API  для взаимодействия с микросервисом:
* **GET** `/metrics` -  Получение списка всех метрик (согласно критериям пагинации).
**GET** `/metrics/{id}`- Получение конкретной метрики по ее идентификатору.

Подробнее с API можно ознакомиться по следующим ссылкам ( **после запуска приложения** ):
* `API Producer`: http://localhost:8090/swagger-ui.html
* `API Consumer`: http://localhost:8091/swagger-ui.html

## Запуск приложения
Для запуска проекта в docker контейнере нужно выполнить команду:
- `docker compose up -d`

При возникновении проблем во время разворачивании сервиса **Kafka** почистите **volumes** используя следующие команды:
- `docker volume rm monitoringsystemsusingspringkafka_kafka_gorch`

## Особенности работы приложения
### Структура БД
![Структура БД.png](docs%2F%D0%A1%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0%20%D0%91%D0%94.png)

Для хранения метрик используется реляционная база данных **PostgreSQL**.
Запросы к БД оптимизированны. Получение данных о метрике и входящих в нее измерениях (Measurements) производится
за один запрос к БД. Данный функционал реализован за счет использования **EntityGraph**.
Сохранение в БД также оптимизированно и производится отправкой пакетов содержащих несколько команд на сохранение записей. 

Для отслеживания того что отправка в БД идет пакетами в файле `application.properties` следует раскоментировать строку:
- `spring.jpa.properties.hibernate.generate_statistics=true`

### Структура **Kafka**

В **Kafka** реализованы 2 топика:
- `metrics-topic` - принимает сообщения от сервиса **producer** и отдает сервису **consumer**
- `metrics-topic.DLT` - принимает сообщения которые не смог десериализовать **consumer**, для дальнейшего анализа и обработки

Основная настройка конфигурации **Kafka** выполнена в файлах `application.properties` соответствующих микросервисов. 
При отправке сообщений из **producer** используется `JsonSerializer`.
Полученные **consumer** сообщения десериализуются с помощью `StringDeserializer`, после чего с помощью библиотеки
`Jackson` в модель `Metric`.
Для повышения производительности получение сообщений сервисом **consumer** осуществляется пакетами.




